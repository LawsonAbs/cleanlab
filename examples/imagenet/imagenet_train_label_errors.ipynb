{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find label errors in ImageNet train set using confident learning\n",
    "\n",
    "### Note this code assumes that you've already computed psx -- the predicted probabilities for all examples in the training set using four-fold cross-validation. If you have no done that you will need to use `imagenet_train_crossval.py` to do this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These imports enhance Python2/3 compatibility.\n",
    "from __future__ import print_function, absolute_import, division, unicode_literals, with_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common ML stuff\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cleanlab\n",
    "import cleanlab\n",
    "from cleanlab import baseline_methods\n",
    "\n",
    "# System modules\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# PyTorch modules\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, savefig=False):\n",
    "    '''Show a grid of images.'''\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.gca().xaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "    if savefig:\n",
    "        plt.savefig('imagenet_figure_32.png', dpi=300, pad_inches=0.0, bbox_inches='tight')\n",
    "    \n",
    "def make3d(img_arr):\n",
    "    '''Reshape images to include a third dimensions for numpy.'''\n",
    "    img_arr = np.asarray(img_arr)\n",
    "    return np.stack((img_arr,)*3, -1) if len(img_arr.shape) < 3 else img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib2 for python2 and python3\n",
    "try:\n",
    "    # For Python 3.0 and later\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    # Fall back to Python 2's urllib2\n",
    "    from urllib2 import urlopen\n",
    "    \n",
    "# simple label names for ImageNet\n",
    "url = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "f = urlopen(url)\n",
    "simple_labels = json.loads('\\n'.join(i.decode('ascii') for i in f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/datasets/imagenet/imagenet__train__model_resnet50__pyx.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2c8cf3731583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/datasets/datasets/imagenet/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraindir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"train/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpsx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"imagenet__train__model_resnet50__pyx.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m  \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/datasets/imagenet/imagenet__train__model_resnet50__pyx.npy'"
     ]
    }
   ],
   "source": [
    "# Load psx, labels, and image locations\n",
    "data_dir = \"/datasets/datasets/imagenet/\"\n",
    "traindir = data_dir + \"train/\"\n",
    "psx = np.load(data_dir + \"imagenet__train__model_resnet50__pyx.npy\") # 这个文件是用于做什么的？\n",
    "imgs, labels = [list(z) for  z in zip(*datasets.ImageFolder(traindir).imgs)]\n",
    "labels = np.array(labels, dtype=int)\n",
    "print('Overall accuracy: {:.2%}'.format(accuracy_score(labels, psx.argmax(axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes ~3 minutes on a 20-thread processor for ImageNet train set.\n",
    "already_computed = False\n",
    "if already_computed:\n",
    "    label_errors_bool = ~np.load(\"/home/cgn/masks/imagenet_train_bool_mask.npy\")\n",
    "else:\n",
    "    label_errors_bool = cleanlab.pruning.get_noise_indices(\n",
    "        s = labels,\n",
    "        psx = psx,\n",
    "        prune_method = 'prune_by_noise_rate',\n",
    "        sorted_index_method=None,\n",
    "    )\n",
    "#     np.save(\"imagenet_train_bool_mask.npy\", ~label_errors_bool) # Store false for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_errors_idx = cleanlab.pruning.order_label_errors(\n",
    "    label_errors_bool = label_errors_bool,\n",
    "    psx = psx,\n",
    "    labels = labels,\n",
    "    sorted_index_method = 'normalized_margin',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of errors to store labels and images for.\n",
    "# Here we only print the first three, but we will print all of them later on.\n",
    "num2print = 32\n",
    "\n",
    "# Import this here because this version of Image is used to print a single image\n",
    "from IPython.display import Image, display\n",
    "fns = []\n",
    "given = []\n",
    "pred = []\n",
    "for i, idx in enumerate(label_errors_idx[:num2print]):\n",
    "    fn = imgs[idx]\n",
    "    fns.append(fn)\n",
    "    given.append(simple_labels[labels[idx]])\n",
    "    pred.append(simple_labels[np.argmax(psx[idx])])\n",
    "    # Print out the first 3 examples\n",
    "    if i < 3:\n",
    "        print(\"Given:\", given[-1].upper()) \n",
    "        print(\"Guess:\", pred[-1].upper())\n",
    "        print(fn.split(\"/\")[-1])\n",
    "        sys.stdout.flush()\n",
    "        display(Image(filename=fn))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now re-import Image from PIL. PIL Image module displays grids of images.\n",
    "from PIL import Image\n",
    "num2print = 32\n",
    "image_size = 333\n",
    "save_figure = False\n",
    "\n",
    "rs = transforms.Resize((333,333))\n",
    "\n",
    "plt.figure(figsize=(50,40))\n",
    "fns = [imgs[i] for i in label_errors_idx[:num2print]]  # Filenames of errors\n",
    "imglist = [transforms.ToTensor()(make3d(rs(Image.open(fn)))) for fn in fns]\n",
    "show(make_grid(imglist, padding=1, normalize=True), savefig=save_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rows of images with captions\n",
    "\n",
    "def padtext(s, l = 27): # 27 works well\n",
    "    return s + \" \" * (l - len(s))\n",
    "\n",
    "rows2print = 4\n",
    "num_per_row = int(num2print / rows2print)\n",
    "for i in range(rows2print):\n",
    "    plt.figure(figsize=(30,10))\n",
    "    imglist = [transforms.ToTensor()(make3d(rs(Image.open(fn)))) for fn in fns[\n",
    "        num_per_row * i : num_per_row * i + num_per_row]]\n",
    "    show(make_grid(imglist, padding=1, normalize=True))\n",
    "    plt.show()\n",
    "    for z in given[num_per_row * i :num_per_row * i + num_per_row]:\n",
    "        item = \" GIVEN: \" + z\n",
    "        print(padtext(item), end = \"\")\n",
    "    print()\n",
    "    for z in pred[num_per_row * i :num_per_row * i + num_per_row]:\n",
    "        item = \" GUESS: \" + z\n",
    "        print(padtext(item), end = \"\")\n",
    "    print()\n",
    "    for z in fns[num_per_row * i:num_per_row * i + num_per_row]:\n",
    "        item = \" \" + fn.split(\"/\")[-1]\n",
    "        print(padtext(item), end = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This concludes the tutorial for displaying imagenet label errors. The code below is for reproducing the label errors in the confiding learning paper: https://arxiv.org/abs/1911.00068"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create multiple files storing the indices of errors for the top 20% of errors, top 40% of errors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the opposite of the stored file (errors should be true, not false)\n",
    "label_errors_bool = ~np.load(\"imagenet_train_bool_mask.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_errors_idx = cleanlab.pruning.order_label_errors(\n",
    "    label_errors_bool = label_errors_bool,\n",
    "    psx = psx,\n",
    "    labels = labels,\n",
    "    sorted_index_method = 'normalized_margin',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates seperate files for the top 20% errors, 40% errors,...\n",
    "for i in range(1,5):\n",
    "    # Prepare arguments\n",
    "    amt = str(100 * i // 5)\n",
    "    end_idx = len(label_errors_idx) * i // 5\n",
    "    partial_errors_idx = label_errors_idx[:end_idx]\n",
    "    # Create new bool mask\n",
    "    bool_mask = np.zeros(len(label_errors_bool), dtype=bool)\n",
    "    bool_mask[partial_errors_idx] = True\n",
    "    # Validate\n",
    "    assert(all(np.array([i for i, b in enumerate(bool_mask) if b]) == sorted(partial_errors_idx)))\n",
    "    print(amt, end_idx)\n",
    "    np.save(\"imagenet_train_bool_mask__fraction_{}.npy\".format(amt), ~bool_mask)\n",
    "    \n",
    "# Verify written files\n",
    "for i in range(1, 5):\n",
    "    amt = str(100 * i // 5)\n",
    "    end_idx = len(label_errors_idx) * i // 5\n",
    "    truth = np.array(sorted(label_errors_idx[:end_idx]))\n",
    "    us = np.array([i for i, b in enumerate(~np.load(\"imagenet_train_bool_mask__fraction_{}.npy\".format(amt))) if b])\n",
    "    assert(all(truth == us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create these files for various methods of finding label errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confident joint only method for getting label errors\n",
    "label_error_mask = np.zeros(len(labels), dtype=bool)\n",
    "label_error_indices = cleanlab.latent_estimation.compute_confident_joint(\n",
    "    labels, psx, return_indices_of_off_diagonals=True\n",
    ")[1]\n",
    "for idx in label_error_indices:\n",
    "    label_error_mask[idx] = True\n",
    "label_errors_bool_cj_only = label_error_mask\n",
    "\n",
    "label_errors_bool_both = cleanlab.pruning.get_noise_indices(\n",
    "    s = labels,\n",
    "    psx = psx,\n",
    "    prune_method = 'both',\n",
    "    sorted_index_method=None,\n",
    ")\n",
    "\n",
    "label_errors_bool_pbc = cleanlab.pruning.get_noise_indices(\n",
    "    s = labels,\n",
    "    psx = psx,\n",
    "    prune_method = 'prune_by_class',\n",
    "    sorted_index_method=None,\n",
    ")\n",
    "\n",
    "label_errors_bool_pbnr = cleanlab.pruning.get_noise_indices(\n",
    "    s = labels,\n",
    "    psx = psx,\n",
    "    prune_method = 'prune_by_noise_rate',\n",
    "    sorted_index_method=None,\n",
    ")\n",
    "\n",
    "label_errors_bool_argmax = baseline_methods.baseline_argmax(psx, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_idx_both = cleanlab.pruning.order_label_errors(label_errors_bool_both, psx, labels)\n",
    "le_idx_pbc = cleanlab.pruning.order_label_errors(label_errors_bool_pbc, psx, labels)\n",
    "le_idx_pbnr = cleanlab.pruning.order_label_errors(label_errors_bool_pbnr, psx, labels)\n",
    "le_idx_argmax = cleanlab.pruning.order_label_errors(label_errors_bool_argmax, psx, labels)\n",
    "le_idx_cj_only = cleanlab.pruning.order_label_errors(label_errors_bool_cj_only, psx, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, label_errors_idx in {\n",
    "#     'both': le_idx_both,\n",
    "#     'argmax': le_idx_argmax,\n",
    "#     'cj_only': le_idx_cj_only,\n",
    "    'cl_pbnr': le_idx_pbnr,\n",
    "    'cl_pbc': le_idx_pbc,\n",
    "}.items():\n",
    "    # Creates seperate files for the top 20% errors, 40% errors,...\n",
    "    for i in range(1,6):\n",
    "        # Prepare arguments\n",
    "        amt = str(100 * i // 5)\n",
    "        end_idx = len(label_errors_idx) * i // 5\n",
    "        partial_errors_idx = label_errors_idx[:end_idx]\n",
    "        # Create new bool mask\n",
    "        bool_mask = np.zeros(len(label_errors_bool_both), dtype=bool)\n",
    "        bool_mask[partial_errors_idx] = True\n",
    "        # Validate\n",
    "        assert(all(np.array([i for i, b in enumerate(bool_mask) if b]) == sorted(partial_errors_idx)))\n",
    "        print(amt, end_idx)\n",
    "        np.save(\"/home/cgn/masks/imagenet_train_bool_{}_mask__fraction_{}.npy\".format(key, amt), ~bool_mask)\n",
    "\n",
    "    # Verify written files\n",
    "    for i in range(1, 6):\n",
    "        amt = str(100 * i // 5)\n",
    "        end_idx = len(label_errors_idx) * i // 5\n",
    "        truth = np.array(sorted(label_errors_idx[:end_idx]))\n",
    "        us = np.array([i for i, b in enumerate(~np.load(\"/home/cgn/masks/imagenet_train_bool_{}_mask__fraction_{}.npy\".format(key, amt))) if b])\n",
    "        assert(all(truth == us))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
